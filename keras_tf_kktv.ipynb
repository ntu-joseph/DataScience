{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 整理資料\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 繪圖\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 日期時間\n",
    "import datetime as dt\n",
    "\n",
    "# 產生隨機數\n",
    "import random\n",
    "\n",
    "# 進度列，舉例如下\n",
    "# 完成百分比|Progress Bar| 目前項目/總項目 [經過時間<預計完成時間(ETA), 處理速率]\n",
    "# 100%|██████████| 7178/7178 [00:04<00:00, 1534.93it/s]\n",
    "import tqdm\n",
    "\n",
    "# 檔案系統存取\n",
    "from pathlib import Path\n",
    "\n",
    "# 深度學習函式庫\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model, model_from_json, load_model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean & Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "讀入資料形狀為(列, 欄): (57159, 30)\n",
      "\n",
      "N/A data:\n",
      "id              0\n",
      "feature         0\n",
      "time_slot_0     0\n",
      "time_slot_1     0\n",
      "time_slot_2     0\n",
      "time_slot_3     0\n",
      "time_slot_4     0\n",
      "time_slot_5     0\n",
      "time_slot_6     0\n",
      "time_slot_7     0\n",
      "time_slot_8     0\n",
      "time_slot_9     0\n",
      "time_slot_10    0\n",
      "time_slot_11    0\n",
      "time_slot_12    0\n",
      "time_slot_13    0\n",
      "time_slot_14    0\n",
      "time_slot_15    0\n",
      "time_slot_16    0\n",
      "time_slot_17    0\n",
      "time_slot_18    0\n",
      "time_slot_19    0\n",
      "time_slot_20    0\n",
      "time_slot_21    0\n",
      "time_slot_22    0\n",
      "time_slot_23    0\n",
      "time_slot_24    0\n",
      "time_slot_25    0\n",
      "time_slot_26    0\n",
      "time_slot_27    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature</th>\n",
       "      <th>time_slot_0</th>\n",
       "      <th>time_slot_1</th>\n",
       "      <th>time_slot_2</th>\n",
       "      <th>time_slot_3</th>\n",
       "      <th>time_slot_4</th>\n",
       "      <th>time_slot_5</th>\n",
       "      <th>time_slot_6</th>\n",
       "      <th>time_slot_7</th>\n",
       "      <th>...</th>\n",
       "      <th>time_slot_18</th>\n",
       "      <th>time_slot_19</th>\n",
       "      <th>time_slot_20</th>\n",
       "      <th>time_slot_21</th>\n",
       "      <th>time_slot_22</th>\n",
       "      <th>time_slot_23</th>\n",
       "      <th>time_slot_24</th>\n",
       "      <th>time_slot_25</th>\n",
       "      <th>time_slot_26</th>\n",
       "      <th>time_slot_27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            feature  time_slot_0  \\\n",
       "0   0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...            0   \n",
       "1   1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...            0   \n",
       "2   2  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...            0   \n",
       "3   3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...            0   \n",
       "4   4  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...            0   \n",
       "\n",
       "   time_slot_1  time_slot_2  time_slot_3  time_slot_4  time_slot_5  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            1            0            0            0            0   \n",
       "3            1            1            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   time_slot_6  time_slot_7      ...       time_slot_18  time_slot_19  \\\n",
       "0            0            0      ...                  0             0   \n",
       "1            0            0      ...                  0             0   \n",
       "2            0            0      ...                  0             0   \n",
       "3            0            0      ...                  0             0   \n",
       "4            0            0      ...                  0             0   \n",
       "\n",
       "   time_slot_20  time_slot_21  time_slot_22  time_slot_23  time_slot_24  \\\n",
       "0             1             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             1   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   time_slot_25  time_slot_26  time_slot_27  \n",
       "0             0             0             0  \n",
       "1             0             0             0  \n",
       "2             0             0             0  \n",
       "3             1             1             0  \n",
       "4             0             0             0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "input_data_x = pd.read_csv('./train_X.csv')\n",
    "\n",
    "input_data_y = pd.read_csv('./all_label.csv')\n",
    "input_data_y = input_data_y.drop('user_id', axis=1)\n",
    "\n",
    "train_data = pd.concat([input_data_x, input_data_y], axis=1)\n",
    "# Preview data shape\n",
    "print('讀入資料形狀為(列, 欄):', train_data.values.shape)\n",
    "\n",
    "# check N/A data (must = 0)\n",
    "print('\\nN/A data:\\n' + str(train_data.isnull().sum()))\n",
    "\n",
    "# Preview Shuffled data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(VALIDATION_SIZE, source_feature, source_label, normalize = True):\n",
    "    if (len(source_feature) != len(source_label)):\n",
    "        raise Exception('Feature length not equals Label length!!')\n",
    "        \n",
    "    VALIDATION_SIZE = int(round(VALIDATION_SIZE * len(source_feature), 0))\n",
    "    #print(VALIDATION_SIZE)\n",
    "    \n",
    "    x = np.vstack(source_feature.apply(lambda im: np.fromstring(im, sep=' ')).values)\n",
    "    y = np.array(source_label)\n",
    "    \n",
    "    # Normalize [0:255] to [0:1]\n",
    "    # 可提升準確率且可加快收斂速率\n",
    "    if (normalize):\n",
    "        x = np.multiply(x, 1.0/255.0)\n",
    "    \n",
    "    x_train = x[VALIDATION_SIZE:]\n",
    "    y_train = y[VALIDATION_SIZE:]\n",
    "\n",
    "    print('The number of final training data: %d'%(len(x_train)))\n",
    "    print(x_train.shape, y_train.shape)\n",
    "    \n",
    "    x_vaild = x[:VALIDATION_SIZE]\n",
    "    y_vaild = y[:VALIDATION_SIZE]\n",
    "\n",
    "    print('\\nThe number of final validation data: %d'%(len(x_vaild)))\n",
    "    print(x_vaild.shape, y_vaild.shape)\n",
    "    \n",
    "    return x_train ,y_train, x_vaild, y_vaild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of final training data: 54301\n",
      "(54301, 924) (54301, 28)\n",
      "\n",
      "The number of final validation data: 2858\n",
      "(2858, 924) (2858, 28)\n"
     ]
    }
   ],
   "source": [
    "# shuffle the rows\n",
    "train_data = train_data.iloc[np.random.permutation(len(train_data))]\n",
    "\n",
    "x_train ,y_train, x_vaild, y_vaild = split_data(0.05, train_data['feature'], train_data.iloc[:, 2:30], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54301, 33, 28, 1), (2858, 33, 28, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將feature重新塑形成為 [輸入圖像數，圖像寬度，圖像高度，色彩通道數(每一色彩 1bit)]\n",
    "height = 33 \n",
    "width = 28\n",
    "\n",
    "x_train = x_train.reshape(-1, height, width, 1)\n",
    "x_vaild = x_vaild.reshape(-1, height, width, 1)\n",
    "x_train.shape, x_vaild.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54301, 28), (2858, 28))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將label重新塑形成為 One-hot表示法\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_vaild = np_utils.to_categorical(y_vaild)\n",
    "y_train.shape, y_vaild.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAGoCAYAAADsCuuWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyP8CpQvenAtUg6cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a248adfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(12,6))\n",
    "for i in range(1, 13):\n",
    "    plt.subplot(3,4,i)\n",
    "    plt.imshow(x_train[i, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/jupyter/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/user/jupyter/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 33, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              3671040   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 3,718,556\n",
      "Trainable params: 3,718,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                input_shape=(height, width ,1),\n",
    "                activation='relu',\n",
    "                padding='same'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                activation='relu',\n",
    "                padding='same'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(28, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# WARNING: ...... keep_dims is deprecated, use keepdims instead will be repaired by keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"848pt\" viewBox=\"0.00 0.00 263.00 848.00\" width=\"263pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 844)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-844 259,-844 259,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140162573873896 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140162573873896</title>\n",
       "<polygon fill=\"none\" points=\"18,-803.5 18,-839.5 237,-839.5 237,-803.5 18,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-817.8\">conv2d_1_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140162573875520 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140162573875520</title>\n",
       "<polygon fill=\"none\" points=\"52,-730.5 52,-766.5 203,-766.5 203,-730.5 52,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-744.8\">conv2d_1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140162573873896&#45;&gt;140162573875520 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140162573873896-&gt;140162573875520</title>\n",
       "<path d=\"M127.5,-803.313C127.5,-795.289 127.5,-785.547 127.5,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-776.529 127.5,-766.529 124,-776.529 131,-776.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140162573873616 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140162573873616</title>\n",
       "<polygon fill=\"none\" points=\"49,-657.5 49,-693.5 206,-693.5 206,-657.5 49,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-671.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 140162573875520&#45;&gt;140162573873616 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140162573875520-&gt;140162573873616</title>\n",
       "<path d=\"M127.5,-730.313C127.5,-722.289 127.5,-712.547 127.5,-703.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-703.529 127.5,-693.529 124,-703.529 131,-703.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140162573875072 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140162573875072</title>\n",
       "<polygon fill=\"none\" points=\"0,-584.5 0,-620.5 255,-620.5 255,-584.5 0,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-598.8\">max_pooling2d_1: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 140162573873616&#45;&gt;140162573875072 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140162573873616-&gt;140162573875072</title>\n",
       "<path d=\"M127.5,-657.313C127.5,-649.289 127.5,-639.547 127.5,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-630.529 127.5,-620.529 124,-630.529 131,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140162573873392 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140162573873392</title>\n",
       "<polygon fill=\"none\" points=\"52,-511.5 52,-547.5 203,-547.5 203,-511.5 52,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-525.8\">conv2d_2: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140162573875072&#45;&gt;140162573873392 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140162573875072-&gt;140162573873392</title>\n",
       "<path d=\"M127.5,-584.313C127.5,-576.289 127.5,-566.547 127.5,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-557.529 127.5,-547.529 124,-557.529 131,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140162574027352 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140162574027352</title>\n",
       "<polygon fill=\"none\" points=\"49,-438.5 49,-474.5 206,-474.5 206,-438.5 49,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-452.8\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 140162573873392&#45;&gt;140162574027352 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140162573873392-&gt;140162574027352</title>\n",
       "<path d=\"M127.5,-511.313C127.5,-503.289 127.5,-493.547 127.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-484.529 127.5,-474.529 124,-484.529 131,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140162575814840 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140162575814840</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 255,-401.5 255,-365.5 0,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-379.8\">max_pooling2d_2: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 140162574027352&#45;&gt;140162575814840 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140162574027352-&gt;140162575814840</title>\n",
       "<path d=\"M127.5,-438.313C127.5,-430.289 127.5,-420.547 127.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-411.529 127.5,-401.529 124,-411.529 131,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140162573981400 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140162573981400</title>\n",
       "<polygon fill=\"none\" points=\"57,-292.5 57,-328.5 198,-328.5 198,-292.5 57,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-306.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 140162575814840&#45;&gt;140162573981400 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140162575814840-&gt;140162573981400</title>\n",
       "<path d=\"M127.5,-365.313C127.5,-357.289 127.5,-347.547 127.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-338.529 127.5,-328.529 124,-338.529 131,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140162574805256 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140162574805256</title>\n",
       "<polygon fill=\"none\" points=\"49,-219.5 49,-255.5 206,-255.5 206,-219.5 49,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-233.8\">dropout_3: Dropout</text>\n",
       "</g>\n",
       "<!-- 140162573981400&#45;&gt;140162574805256 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140162573981400-&gt;140162574805256</title>\n",
       "<path d=\"M127.5,-292.313C127.5,-284.289 127.5,-274.547 127.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-265.529 127.5,-255.529 124,-265.529 131,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140162574107144 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140162574107144</title>\n",
       "<polygon fill=\"none\" points=\"63.5,-146.5 63.5,-182.5 191.5,-182.5 191.5,-146.5 63.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-160.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140162574805256&#45;&gt;140162574107144 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140162574805256-&gt;140162574107144</title>\n",
       "<path d=\"M127.5,-219.313C127.5,-211.289 127.5,-201.547 127.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-192.529 127.5,-182.529 124,-192.529 131,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140162574805984 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140162574805984</title>\n",
       "<polygon fill=\"none\" points=\"49,-73.5 49,-109.5 206,-109.5 206,-73.5 49,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-87.8\">dropout_4: Dropout</text>\n",
       "</g>\n",
       "<!-- 140162574107144&#45;&gt;140162574805984 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140162574107144-&gt;140162574805984</title>\n",
       "<path d=\"M127.5,-146.313C127.5,-138.289 127.5,-128.547 127.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-119.529 127.5,-109.529 124,-119.529 131,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140162573796464 -->\n",
       "<g class=\"node\" id=\"node12\"><title>140162573796464</title>\n",
       "<polygon fill=\"none\" points=\"63.5,-0.5 63.5,-36.5 191.5,-36.5 191.5,-0.5 63.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140162574805984&#45;&gt;140162573796464 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>140162574805984-&gt;140162573796464</title>\n",
       "<path d=\"M127.5,-73.3129C127.5,-65.2895 127.5,-55.5475 127.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-46.5288 127.5,-36.5288 124,-46.5289 131,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# save best weights\n",
    "output_dir = './' + dt.datetime.now().strftime(\"%Y%m%d\")\n",
    "path = Path(output_dir)\n",
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "\n",
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model).create(prog=\"dot\", format=\"svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#model = load_model('.//keras_tf_easy//20171103002518_model_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54301 samples, validate on 2858 samples\n",
      "Epoch 1/20\n",
      "54100/54301 [============================>.] - ETA: 0s - loss: 0.1818 - acc: 0.9336Epoch 00001: val_loss improved from inf to 0.14106, saving model to .\\keras_tf_x_ray\\20180118//model.h5\n",
      "54301/54301 [==============================] - 7s 135us/step - loss: 0.1817 - acc: 0.9337 - val_loss: 0.1411 - val_acc: 0.9535\n",
      "Epoch 2/20\n",
      "54100/54301 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9553Epoch 00002: val_loss improved from 0.14106 to 0.12282, saving model to .\\keras_tf_x_ray\\20180118//model.h5\n",
      "54301/54301 [==============================] - 7s 122us/step - loss: 0.1323 - acc: 0.9553 - val_loss: 0.1228 - val_acc: 0.9660\n",
      "Epoch 3/20\n",
      "54100/54301 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9617Epoch 00003: val_loss improved from 0.12282 to 0.11198, saving model to .\\keras_tf_x_ray\\20180118//model.h5\n",
      "54301/54301 [==============================] - 7s 125us/step - loss: 0.1197 - acc: 0.9617 - val_loss: 0.1120 - val_acc: 0.9703\n",
      "Epoch 4/20\n",
      "54200/54301 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9649Epoch 00004: val_loss improved from 0.11198 to 0.10770, saving model to .\\keras_tf_x_ray\\20180118//model.h5\n",
      "54301/54301 [==============================] - 7s 123us/step - loss: 0.1126 - acc: 0.9649 - val_loss: 0.1077 - val_acc: 0.9711\n",
      "Epoch 5/20\n",
      "54200/54301 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9669Epoch 00005: val_loss did not improve\n",
      "54301/54301 [==============================] - 6s 117us/step - loss: 0.1076 - acc: 0.9669 - val_loss: 0.1082 - val_acc: 0.9726\n",
      "Epoch 6/20\n",
      "54000/54301 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9683Epoch 00006: val_loss improved from 0.10770 to 0.10412, saving model to .\\keras_tf_x_ray\\20180118//model.h5\n",
      "54301/54301 [==============================] - 7s 124us/step - loss: 0.1043 - acc: 0.9683 - val_loss: 0.1041 - val_acc: 0.9738\n",
      "Epoch 7/20\n",
      "54300/54301 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9693Epoch 00007: val_loss improved from 0.10412 to 0.10003, saving model to .\\keras_tf_x_ray\\20180118//model.h5\n",
      "54301/54301 [==============================] - 6s 117us/step - loss: 0.1010 - acc: 0.9693 - val_loss: 0.1000 - val_acc: 0.9744\n",
      "Epoch 8/20\n",
      "54300/54301 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9704Epoch 00008: val_loss improved from 0.10003 to 0.09790, saving model to .\\keras_tf_x_ray\\20180118//model.h5\n",
      "54301/54301 [==============================] - 7s 124us/step - loss: 0.0981 - acc: 0.9704 - val_loss: 0.0979 - val_acc: 0.9747\n",
      "Epoch 9/20\n",
      "54100/54301 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9711Epoch 00009: val_loss improved from 0.09790 to 0.09572, saving model to .\\keras_tf_x_ray\\20180118//model.h5\n",
      "54301/54301 [==============================] - 7s 128us/step - loss: 0.0959 - acc: 0.9711 - val_loss: 0.0957 - val_acc: 0.9744\n",
      "Epoch 10/20\n",
      "53900/54301 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9716Epoch 00010: val_loss did not improve\n",
      "54301/54301 [==============================] - 7s 120us/step - loss: 0.0942 - acc: 0.9716 - val_loss: 0.0963 - val_acc: 0.9749\n",
      "Epoch 11/20\n",
      "54300/54301 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9725Epoch 00011: val_loss improved from 0.09572 to 0.09414, saving model to .\\keras_tf_x_ray\\20180118//model.h5\n",
      "54301/54301 [==============================] - 7s 128us/step - loss: 0.0916 - acc: 0.9725 - val_loss: 0.0941 - val_acc: 0.9752\n",
      "Epoch 12/20\n",
      "54200/54301 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9730Epoch 00012: val_loss did not improve\n",
      "54301/54301 [==============================] - 7s 122us/step - loss: 0.0896 - acc: 0.9730 - val_loss: 0.0942 - val_acc: 0.9752\n",
      "Epoch 13/20\n",
      "54100/54301 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9737Epoch 00013: val_loss did not improve\n",
      "54301/54301 [==============================] - 7s 121us/step - loss: 0.0873 - acc: 0.9737 - val_loss: 0.0985 - val_acc: 0.9721\n",
      "Epoch 14/20\n",
      "53900/54301 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9733Epoch 00014: val_loss did not improve\n",
      "54301/54301 [==============================] - 7s 125us/step - loss: 0.0877 - acc: 0.9734 - val_loss: 0.0944 - val_acc: 0.9748\n",
      "Epoch 15/20\n",
      "54300/54301 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9746Epoch 00015: val_loss did not improve\n",
      "54301/54301 [==============================] - 7s 123us/step - loss: 0.0838 - acc: 0.9746 - val_loss: 0.0942 - val_acc: 0.9748\n",
      "Epoch 16/20\n",
      "54200/54301 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9753Epoch 00016: val_loss did not improve\n",
      "54301/54301 [==============================] - 7s 123us/step - loss: 0.0815 - acc: 0.9753 - val_loss: 0.0961 - val_acc: 0.9748\n",
      "Epoch 17/20\n",
      "54300/54301 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9757Epoch 00017: val_loss did not improve\n",
      "54301/54301 [==============================] - 7s 128us/step - loss: 0.0799 - acc: 0.9757 - val_loss: 0.0952 - val_acc: 0.9742\n",
      "Epoch 18/20\n",
      "54200/54301 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9761Epoch 00018: val_loss did not improve\n",
      "54301/54301 [==============================] - 7s 125us/step - loss: 0.0784 - acc: 0.9761 - val_loss: 0.0965 - val_acc: 0.9745\n",
      "Epoch 19/20\n",
      "54300/54301 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9765Epoch 00019: val_loss did not improve\n",
      "54301/54301 [==============================] - 7s 128us/step - loss: 0.0768 - acc: 0.9765 - val_loss: 0.0964 - val_acc: 0.9743\n",
      "Epoch 20/20\n",
      "54100/54301 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9767Epoch 00020: val_loss did not improve\n",
      "54301/54301 [==============================] - 7s 120us/step - loss: 0.0752 - acc: 0.9768 - val_loss: 0.0957 - val_acc: 0.9742\n",
      "Model saved to: .\\keras_tf_x_ray\\20180118//20180118102143_face_model_final_0.97422.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.095733140649350901, 0.97422024422045606]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkpointer = ModelCheckpoint(filepath=output_dir + '//model.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "#ValueError: If printing histograms, validation_data must be provided, and cannot be a generator.\n",
    "\n",
    "#embeddingsMetadata = {'conv2d_2': 'metadata.tsv'}\n",
    "tensorboard = TensorBoard(log_dir=output_dir, histogram_freq=0, write_graph=True, write_images=False)\n",
    "                          #embeddings_freq=10, embeddings_layer_names = ['conv2d_2'])\n",
    "                          #embeddings_metadata=embeddingsMetadata)\n",
    "\n",
    "# Total epoch = times x step\n",
    "times = 1\n",
    "step = 20\n",
    "\n",
    "for i in range(0, 0 + times):\n",
    "    # num epochs (each epoch about spent 10 mins.)\n",
    "    epochs = i * step + step\n",
    "    \n",
    "    hist = model.fit(x_train, y_train, epochs=epochs, initial_epoch= i * step,\n",
    "                        batch_size=100,validation_data=(x_vaild, y_vaild),\n",
    "                        callbacks=[checkpointer, tensorboard], verbose = 1)\n",
    "\n",
    "    '''\n",
    "    # run model\n",
    "    hist = model.fit(x_train, y_train, epochs=epochs,\n",
    "                     shuffle=True,\n",
    "                     batch_size=100, validation_data=(x_vaild, y_vaild),\n",
    "                     callbacks=[checkpointer], verbose=2)\n",
    "    '''\n",
    "\n",
    "    # create dt object\n",
    "    dtNow = dt.datetime.now().strftime(\"%Y%m%d%H%M%S\");\n",
    "\n",
    "    # save model arch to json\n",
    "    model_json = model.to_json()\n",
    "    with open(output_dir + \"//\" + dtNow + \"_face_model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    # evaluate model\n",
    "    score = model.evaluate(x_vaild, y_vaild, verbose=0)\n",
    "\n",
    "    # save final model\n",
    "    pathStr = output_dir + '//' + dtNow + '_face_model_final_' + str(round(score[1], 6)) + '.h5'\n",
    "    model.save(pathStr)  # creates a HDF5 file\n",
    "    print('Model saved to: {0}'.format(pathStr))\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA08AAADYCAYAAAAztdh8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab97a46358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(hist.history['loss'], color='b', label='Training Loss')\n",
    "plt.plot(hist.history['val_loss'], color='r', label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(hist.history['acc'], color='b', label='Training Accuracy')\n",
    "plt.plot(hist.history['val_acc'], color='r', label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]] [1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_vaild[3], y_vaild[3])\n",
    "predicted_probs = model.predict(x_vaild[3].reshape(-1, height, width, 1))\n",
    "predicted_probs[predicted_probs>=0.5] = 1\n",
    "predicted_probs[predicted_probs<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2858/2858 [00:01<00:00, 1676.94it/s]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = np.zeros((28, 28))\n",
    "\n",
    "misclassified = [list() for i in range(28)]\n",
    "#print(misclassified)\n",
    "answerCount = [0] * 28\n",
    "\n",
    "for image_id, image in tqdm.tqdm(enumerate(zip(x_vaild,y_vaild)), total=len(x_vaild)):\n",
    "    predicted_probs = model.predict(image[0].reshape(-1, height, width, 1))\n",
    "    #predicted = np.argmax(predicted_probs)\n",
    "    #answer = np.argmax(image[1])\n",
    "    predicted_probs[predicted_probs>=0.5] = 1\n",
    "    predicted_probs[predicted_probs<0.5] = 0\n",
    "    \n",
    "    #print(image[1])\n",
    "    #print(predicted_probs[0].astype(int))\n",
    "    #print(predicted_probs[0] == image[1])\n",
    "    \n",
    "    #raise\n",
    "    \n",
    "    for i in range(0, len(answerCount)):\n",
    "        if (image[1][i] == 1):\n",
    "            answerCount[i]+=1\n",
    "\n",
    "        if (image[1][i] != predicted_probs[0][i]):\n",
    "            misclassified[i].append((image[0], image[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 77 out of 307 (25.081%) misclassified\n",
      "1 - 94 out of 472 (19.915%) misclassified\n",
      "2 - 33 out of 132 (25.0%) misclassified\n",
      "3 - 71 out of 118 (60.169%) misclassified\n",
      "4 - 88 out of 358 (24.581%) misclassified\n",
      "5 - 96 out of 459 (20.915%) misclassified\n",
      "6 - 40 out of 134 (29.851%) misclassified\n",
      "7 - 76 out of 118 (64.407%) misclassified\n",
      "8 - 82 out of 351 (23.362%) misclassified\n",
      "9 - 95 out of 497 (19.115%) misclassified\n",
      "10 - 37 out of 120 (30.833%) misclassified\n",
      "11 - 79 out of 111 (71.171%) misclassified\n",
      "12 - 80 out of 302 (26.49%) misclassified\n",
      "13 - 97 out of 470 (20.638%) misclassified\n",
      "14 - 42 out of 121 (34.711%) misclassified\n",
      "15 - 73 out of 109 (66.972%) misclassified\n",
      "16 - 80 out of 329 (24.316%) misclassified\n",
      "17 - 112 out of 449 (24.944%) misclassified\n",
      "18 - 42 out of 123 (34.146%) misclassified\n",
      "19 - 97 out of 120 (80.833%) misclassified\n",
      "20 - 103 out of 353 (29.178%) misclassified\n",
      "21 - 108 out of 435 (24.828%) misclassified\n",
      "22 - 41 out of 147 (27.891%) misclassified\n",
      "23 - 79 out of 108 (73.148%) misclassified\n",
      "24 - 81 out of 329 (24.62%) misclassified\n",
      "25 - 88 out of 414 (21.256%) misclassified\n",
      "26 - 21 out of 121 (17.355%) misclassified\n",
      "27 - 51 out of 64 (79.688%) misclassified\n",
      "Total - 2063 out of 7171 (28.769%) misclassified\n"
     ]
    }
   ],
   "source": [
    "#print(misclassified[1])\n",
    "time_slots = list(range(0, 28))\n",
    "total_misclassified_items = 0\n",
    "total_items = 0\n",
    "for time_slots_id, time_slots_name in enumerate(time_slots):\n",
    "    total_misclassified_items += len(misclassified[time_slots_id])\n",
    "    total_items += answerCount[time_slots_id]\n",
    "    print(\"{0} - {1} out of {2} ({3}%) misclassified\".format(time_slots_name, len(misclassified[time_slots_id]),\n",
    "                                                             answerCount[time_slots_id], round((len(misclassified[time_slots_id])/answerCount[time_slots_id]) * 100, 3)))\n",
    "    \n",
    "print(\"Total - {0} out of {1} ({2}%) misclassified\".format(total_misclassified_items, total_items, round((total_misclassified_items / total_items) * 100, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_disease = 1\n",
    "\n",
    "if len(misclassified[2]) == 0:\n",
    "    print(\"no images to show\")\n",
    "else:\n",
    "    print('Total of images: ', len(misclassified[show_disease]), ', Total of lebals: ', len(misclassified[show_disease]))\n",
    "    #print(cls_true)\n",
    "    \n",
    "    random_indices = random.sample(range(len(misclassified[show_disease])), min(len(misclassified[show_disease]), 25))\n",
    "    #random_indices = list(range(25))\n",
    "    \n",
    "    print(random_indices)\n",
    "\n",
    "# Create figure with 5x5 sub-plots.\n",
    "fig, axes = plt.subplots(5, 4)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "fig.set_size_inches(20, 15)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    #print(i, ax, enumerate(axes.flat))\n",
    "    \n",
    "    # Plot image.\n",
    "    ax.imshow(misclassified[show_disease][random_indices[i]][0][:, :, 0], cmap='gray')\n",
    "\n",
    "    xlabel = \"Index: {0}, True: ({1}){2}, Pred: ({3}){4}\".format(\n",
    "                random_indices[i], np.argmax(misclassified[show_disease][i][1]),\n",
    "                diseases[np.argmax(misclassified[show_disease][i][1])], \n",
    "                misclassified[show_disease][i][2], diseases[misclassified[show_disease][i][2]])\n",
    "\n",
    "    # Show the classes as the label on the x-axis.\n",
    "    ax.set_xlabel(xlabel)\n",
    "    \n",
    "    # Remove ticks from the plot.\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "# Ensure the plot is shown correctly with multiple plots\n",
    "# in a single Notebook cell.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(30, 30)\n",
    "plt.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect(1)\n",
    "\n",
    "#normalized = np.array(confusion_matrix) / confusion_matrix.sum(axis = 1) * 100\n",
    "normalized = np.array([[0.]*28]*28)\n",
    "\n",
    "for i in range(len(confusion_matrix)):\n",
    "    for j in range(len(confusion_matrix[i])):\n",
    "        normalized[i][j] = round(confusion_matrix[i][j] / confusion_matrix.sum (axis = 1) [i] * 100, 2)\n",
    "    \n",
    "total = np.array(confusion_matrix)\n",
    "\n",
    "#print(confusion_matrix.sum(axis=1),\"\\n\",np.array(confusion_matrix))\n",
    "#print(normalized)\n",
    "\n",
    "res = ax.imshow(np.array(normalized), cmap=\"Blues\", \n",
    "                interpolation=\"nearest\")\n",
    "height, width = confusion_matrix.shape\n",
    "cb = fig.colorbar(res)\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        ax.annotate(str(int(total[x][y])) + \"\\n(\" + str(normalized[x][y]) + \"%)\", xy=(y, x), \n",
    "                    horizontalalignment=\"center\",\n",
    "                    verticalalignment=\"center\", \n",
    "                    fontsize=12)\n",
    "\n",
    "plt.xlabel('Predict', fontsize=15)\n",
    "plt.ylabel('Actural', fontsize=15)\n",
    "plt.xticks(range(width), diseases, rotation=\"vertical\", fontsize=15);\n",
    "plt.yticks(range(height), diseases, fontsize=15);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('.//train_X.csv')\n",
    "print(test_data.values.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into testing\n",
    "x_test = np.vstack(train_data['feature'].apply(lambda im: np.fromstring(im, sep=' ')).values)\n",
    "\n",
    "# [0:255] to [0:1]\n",
    "#x_test = np.multiply(x_test,1.0/255.0)\n",
    "\n",
    "print('The number of final testing data: %d'%(len(x_test)))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(-1, 33, 28, 1)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(x_test) < 13):\n",
    "    max_show = len(x_test) + 1\n",
    "else:\n",
    "    max_show = 13\n",
    "\n",
    "plt.figure(0, figsize=(16, 8))\n",
    "for i in range(1, max_show):\n",
    "    plt.subplot(3, 6, i)\n",
    "    plt.imshow(x_test[i - 1, :, :, 0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 0\n",
    "predicted_probs = model.predict(x_test[image_idx:image_idx + 1, : , : ,0:1])\n",
    "predicted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_lables = []\n",
    "\n",
    "for image_id, image in tqdm.tqdm(enumerate(x_test), total = len(x_test)):   \n",
    "    predicted_probs = model.predict(image.reshape(-1, height, width, 1))\n",
    "    predicted = np.argmax(predicted_probs)\n",
    "    predicted_lables.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Index:\", \"0:Angry\", \"1:Disgust\", \"2:Fear\", \"3:Happy\", \"4:Sad\", \"5:Surprise\", \"6:Neutral\")\n",
    "#print('Total: {0}, Result: {1}'.format(len(predicted_lables), predicted_lables))\n",
    "\n",
    "'''\n",
    "# save results\n",
    "np.savetxt('hw3_keras8_submission_softmax.csv',\n",
    "           np.c_[range(0,len(x_test)),predicted_lables],\n",
    "           delimiter=',',\n",
    "           header = 'id,label',\n",
    "           comments = '',\n",
    "           fmt='%d')\n",
    "'''\n",
    "correct = 0\n",
    "\n",
    "for idx, element in enumerate(train_data['label']):\n",
    "    if (element == predicted_lables[i]):\n",
    "        correct = correct + 1\n",
    "\n",
    "print('Test accuracy:{0}%'.format(correct / len(predicted_lables) * 100))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
